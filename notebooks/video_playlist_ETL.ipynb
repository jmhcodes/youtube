{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract, Transform, Load [[ETL]](https://www.stitchdata.com/etldatabase/etl-process/) with the [Youtube Data API](https://developers.google.com/youtube/v3/docs/videos/list?apix_params=%7B%22part%22%3A%5B%22snippet%2CcontentDetails%2Cstatistics%22%5D%2C%22id%22%3A%5B%22Ks-_Mh1QhMc%22%5D%7D)\n",
    "\n",
    "Git doesn't support in text .ipynb hyperlinks, to use them checkout the [nbviewer for this notebook](https://nbviewer.jupyter.org/github/jmhcodes/youtube/blob/master/notebooks/video_playlist_ETL.ipynb)\n",
    "\n",
    "## *Abstract:*   \n",
    "*This notebook extracts all the video info from a specific youtube playlist then transformans and loads it into a postgre db*\n",
    "- You will need a YouTube Data API Key to continue. Obtain one [here](https://console.developers.google.com/apis/credentials?project=youtube-import-282315&folder=&organizationId=) \n",
    "- Recommended soundtrack: [Earth Wind & Fire - I am](https://www.youtube.com/watch?v=6Z2xClustQo&list=PLyLqIRlItpe0SGOR9H66eTXiDSk2OEwDp)\n",
    "\n",
    "### Prerequisites \n",
    "1. Set up Postgres DB on your machine or online platform. \n",
    "    - [Fedora/ Red Hat](https://computingforgeeks.com/how-to-install-postgresql-on-fedora/) + [pgAmin](https://computingforgeeks.com/how-to-install-pgadmin-on-centos-fedora/)\n",
    "    - [Ubuntu](https://www.digitalocean.com/community/tutorials/how-to-install-and-use-postgresql-on-ubuntu-18-04) + [pgAdmin](https://www.e2enetworks.com/help/knowledge-base/install-pgadmin-4-on-ubuntu-16-04/)\n",
    "    - [Win10](https://www.postgresqltutorial.com/install-postgresql/) + [pgAdmin](https://www.pgadmin.org/download/pgadmin-4-windows/)\n",
    "    - [MacOS](https://www.postgresqltutorial.com/install-postgresql-macos/) + [pgAdmin](https://www.pgadmin.org/download/pgadmin-4-macos/)\n",
    "2. [Acquire YouTubeAPI Key](https://rapidapi.com/blog/how-to-get-youtube-api-key/)\n",
    "3. Save your new developerKey and client_secrets_file from acquiring the Youtube API Key in a youtube_config.py\n",
    "    - ***These three steps must be completed before starting this notebook and are explained in my git***\n",
    "\n",
    "## Goals: \n",
    "Git doesn't support in text .ipynb hyperlinks, to use them checkout the [nbviewer for this notebook](https://nbviewer.jupyter.org/github/jmhcodes/youtube/blob/master/notebooks/video_playlist_ETL.ipynb)\n",
    "> ### [Extract](#Extract_main)\n",
    "- [E1.](#E1) Write YouTube Data API query function to pull all videos in a playlist\n",
    "    - [Youtube API Code Examples](https://developers.google.com/youtube/v3/docs/videos/list?apix_params=%7B%22part%22%3A%5B%22snippet%22%5D%2C%22chart%22%3A%22mostPopular%22%2C%22regionCode%22%3A%22US%22%7D#try-it)\n",
    "- [E2.](#E2) Run playlists() function to return playlist.json\n",
    "- [E3.](#E3) Visualize the playlist.json, check it's keys and prep to transform the needed data\n",
    "\n",
    ">### [Transform](#Transform_main)\n",
    "- [T1.](#T1) [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) flatten out our json file. Check out the other kwargs for this it's very convenient\n",
    "- [T2.](#T2) Confirm our [pagination](https://developers.google.com/youtube/v3/guides/implementation/pagination) worked in the extract query by checking df length against total results of playlist json\n",
    "- [T3.](#T3) Begin transforming the DataFrame to exactly what we want to load\n",
    " - [ ] [A.](#T3a) Create clickable a clickable links, take a break and check out a video\n",
    " - [ ] [B.](#T3b) Write and use function to split column names into the desired format\n",
    " - [ ] [C.](#T3c) Cast 'videopublishedat' as a DateTime object\n",
    "\n",
    ">### [Load](#Load_main)\n",
    "- [L1.](#L1) Use psycopg2 to connect to our new Postgre DB\n",
    "- [L2.](#L2) Create a youtube_test DATABASE.\n",
    "- [L3.](#L3) Create playlist TABLE in the new youtube_test DATABASE\n",
    "   -  [ ] [A.](#L3a) We'll have to connect to the new youtube_test DATABASE\n",
    "- [L4.](#L4) Use sqlalchemy to upload our DataFrame to our new playlists table\n",
    "- [L5.](#L5a) Confirm our DataFrame uploaded to our desired location\n",
    "   - [ ] [A.](#L5a) Reconnect with psycopg2\n",
    "   - [ ] [B.](#L5b) Write function to get the column names of the table for our sql_df DataFrame\n",
    "   - [ ] [C.](#L5c) Query the playlists table to view your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import json_normalize\n",
    "from datetime import datetime\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import google_auth_oauthlib.flow\n",
    "import googleapiclient.discovery\n",
    "import googleapiclient.errors\n",
    "import math\n",
    "import webbrowser\n",
    "import random\n",
    "\n",
    "#You'll need to create a youtube_config.py that stores your API key\n",
    "#Within youtube_config.py it should store: developerKey=developerKey, client_secrets_file=pwd/client_secrets_file.json\n",
    "import youtube_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Extract_main'></a>\n",
    "### Extract\n",
    "*E1. Write YouTube Data API query function to pull all the videos in a playlist*\n",
    "\n",
    "*E2. Run playlists() function to return playlist.json*\n",
    "\n",
    "*E3. Visualize the playlist.json, check it's keys and prep to transform the needed data*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='E1'></a>\n",
    "#### E1. Write YouTube Data API query function to pull all the videos in a playlist\n",
    "\n",
    "> ###### Below is a Youtube API query with pagination to retrieve all videos in lists>50. [Youtube API Code Examples](https://developers.google.com/youtube/v3/docs/videos/list?apix_params=%7B%22part%22%3A%5B%22snippet%22%5D%2C%22chart%22%3A%22mostPopular%22%2C%22regionCode%22%3A%22US%22%7D#try-it)\n",
    "- by default the API only returns 50 records per page so you have to paginate to the next page for the rest or the results\n",
    "- the response['nextPageToken'] key is used in playlists() for pagination to pull all results after the first page\n",
    " - if youre interested in learning more about how pagination works in the youtube API check it out [here](https://developers.google.com/youtube/v3/guides/implementation/pagination)\n",
    "\n",
    "#### *important note: you need to paste your API key into the developerKey variable*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "# See instructions for running these code samples locally:\n",
    "# https://developers.google.com/explorer-help/guides/code_samples#python\n",
    "scopes = [\"https://www.googleapis.com/auth/youtube.readonly\"]\n",
    "\n",
    "def playlists(plid=None, pageToken = None):\n",
    "    # Disable OAuthlib's HTTPS verification when running locally.\n",
    "    # *DO NOT* leave this option enabled in production.\n",
    "    os.environ[\"OAUTHLIB_INSECURE_TRANSPORT\"] = \"1\"\n",
    "\n",
    "    api_service_name = \"youtube\"\n",
    "    api_version = \"v3\"\n",
    "    developerKey = youtube_config.developerKey\n",
    "    \n",
    "    client_secrets_file = youtube_config.client_secrets_file\n",
    "\n",
    "    \n",
    "    #The following section can be changed to utilize OAuth and the client_secrets_file if wanted. We use the API key instead\n",
    "    # Get credentials and create an API client\n",
    "    #flow = google_auth_oauthlib.flow.InstalledAppFlow.from_client_secrets_file(\n",
    "    #    client_secrets_file, scopes)\n",
    "    #credentials = flow.run_console()\n",
    "   \n",
    "    youtube = googleapiclient.discovery.build(\n",
    "        api_service_name, api_version, developerKey=developerKey)\n",
    "\n",
    "    #request first page of playlist videos\n",
    "    request = youtube.playlistItems().list(\n",
    "        part=\"snippet,contentDetails\",\n",
    "        maxResults=50,\n",
    "        playlistId=plid, \n",
    "        pageToken = pageToken\n",
    "    )\n",
    "    response = request.execute()\n",
    "    r_old_playlists = response.copy()\n",
    "    \n",
    "    #request the remaning pages of playlist videos via nextPageToken pagination\n",
    "    while 'nextPageToken' in response:\n",
    "        pageToken = response['nextPageToken']\n",
    "        request = youtube.playlistItems().list(\n",
    "            part=\"snippet,contentDetails\",\n",
    "            maxResults=50,\n",
    "            playlistId=plid, \n",
    "            pageToken = pageToken\n",
    "        )\n",
    "        response = request.execute()\n",
    "        r_old_playlists['items'] = r_old_playlists['items'] + response['items']\n",
    "               \n",
    "    return r_old_playlists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*E1. Write YouTube Data API query function to pull all the videos in a playlist*\n",
    "<a id='E2'></a>\n",
    "#### E2. Run playlists() function to return playlist.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You'll need to click on the link below with a youtube account signed in and proceed to the unverified app \n",
    "#Soon itll be verified\n",
    "#you need to find the playlist id for your favorite playlist and enter it here\n",
    "yt_json = playlists(plid=\"PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*E1. Write YouTube Data API query function to pull all the videos in a playlist*\n",
    "\n",
    "*E2. Run playlists() function to return playlist.json*\n",
    "<a id='E3'></a>\n",
    "\n",
    "**E3. Visualize the playlist.json, check it's keys and see prep to transform the needed data**\n",
    "\n",
    ">### Let's take a look at the json and its keys\n",
    " - Overall its a pretty clean json and should flatten nicely into a df for us to insert into postgre. \n",
    " - Check out the yt_json.keys()\n",
    " > 1. yt_json['kind'] is the type of YouTube Data API object returned: youtube#playlistItemListResponse\n",
    " > 2.  yt_json['etag'] is the etag of the playlist: v0T_wMbw983TuSWNE80dymxMv6c\n",
    " > 3. yt_json['nextPageToken'] will have the next page of videos. The first page after the original is CDIQAA\n",
    " > 4. yt_json['items'], this contains the video info we are interested in\n",
    "    - **The video info we want is in the 'items' key. It has loads of cool info like:**  <br>\n",
    "        - kind, etag, publishedAt, title, description, channelTitle, playlistId, resourceId\n",
    " > 5. yt_json['pageInfo']has total # of videos and current # returned: {'totalResults': 311, 'resultsPerPage': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yt_json.json dict keys:\n",
      " \t 1. kind\n",
      " \t 2. etag\n",
      " \t 3. nextPageToken\n",
      " \t 4. items\n",
      " \t 5. pageInfo\n",
      "\t \t 1. yt_json['kind'] YouTube Data API object returned: youtube#playlistItemListResponse\n",
      "\t \t 2. yt_json['etag'] is the etag of the playlist sh4VWFJOkpmbaG8MbWuYHbQPJeI\n",
      "\t \t 3. yt_json['nextPageToken'] will have the next page of videos CDIQAA\n",
      "\t \t 5. yt_json['pageInfo']has total # of videos and current # returned {'totalResults': 311, 'resultsPerPage': 50}\n",
      "\u001b[1m\n",
      " \t \t 4. yt_json['items'], this contains the video info we are interested in:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'kind': 'youtube#playlistItem',\n",
       " 'etag': 'JFzB7xf4Hx7Ji8Sf6KNAlCvsj50',\n",
       " 'id': 'UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby41NkI0NEY2RDEwNTU3Q0M2',\n",
       " 'snippet': {'publishedAt': '2017-08-13T00:19:12Z',\n",
       "  'channelId': 'UCqjLgu2L35BoHNnhQLzmlfQ',\n",
       "  'title': 'Yee',\n",
       "  'description': 'Dinosauri bisesti dalle voci funeste. Original title: \"I dinosauri antropomorfi hanno il sangue nel ritmo\" (literally \"The anthropomorphic dinosaurs have blood in their rhythm\"), as opposite to http://youtu.be/e6MLjaKhp5U\\nIf you are that \"wtf this is so funny i want to know shit\"-type of person, here\\'s some info/faq:\\n- original cartoon: https://youtu.be/brLqiYj5lQw\\n- original song: http://youtu.be/v_XJIsDJgXc?t=4m1s (at 4:01)\\n- original yee: https://youtu.be/hCKQP9IHHcA\\n- \"is this a remix?\" sort of. i arranged the dinos so that they would sing along with the music and that\\'s it\\n- \"why does the dino say yee?\" in the original footage he was calling the other dinosaur by name (\"Peek\")\\n- \"fuck everything! i went through the whole movie and there was no yee sound! i hate my life\" dude, yee is only in the italian version of the movie, ciao ciao pizza ferrari\\n- \"is the italian dub as atrocious as the english one?\" you bet\\n- \"why did you make this video?\" i was trying to make a burrito out of your stupid questions and this happened\\n- \"how did this become so popular?\" illuminati',\n",
       "  'thumbnails': {'default': {'url': 'https://i.ytimg.com/vi/q6EoRBvdVPQ/default.jpg',\n",
       "    'width': 120,\n",
       "    'height': 90},\n",
       "   'medium': {'url': 'https://i.ytimg.com/vi/q6EoRBvdVPQ/mqdefault.jpg',\n",
       "    'width': 320,\n",
       "    'height': 180},\n",
       "   'high': {'url': 'https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg',\n",
       "    'width': 480,\n",
       "    'height': 360}},\n",
       "  'channelTitle': 'kierancaspian',\n",
       "  'playlistId': 'PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo',\n",
       "  'position': 0,\n",
       "  'resourceId': {'kind': 'youtube#video', 'videoId': 'q6EoRBvdVPQ'}},\n",
       " 'contentDetails': {'videoId': 'q6EoRBvdVPQ',\n",
       "  'videoPublishedAt': '2012-02-29T19:47:08Z'}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"yt_json.json dict keys:\")\n",
    "i = 1\n",
    "for key in yt_json.keys():\n",
    "    print(' \\t {}. {}'.format(i, key))\n",
    "    i += 1\n",
    "\n",
    "print(\"\\t \\t 1. yt_json['kind'] YouTube Data API object returned: {}\".format(yt_json['kind']))\n",
    "print(\"\\t \\t 2. yt_json['etag'] is the etag of the playlist {}\".format(yt_json['etag']))\n",
    "print(\"\\t \\t 3. yt_json['nextPageToken'] will have the next page of videos {}\".format(yt_json['nextPageToken']))\n",
    "print(\"\\t \\t 5. yt_json['pageInfo']has total # of videos and current # returned {}\".format(yt_json['pageInfo']))\n",
    "print('\\033[1m'+ \"\\n \\t \\t 4. yt_json['items'], this contains the video info we are interested in:\")\n",
    "\n",
    "yt_json['items'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Transform_main'></a>\n",
    "### Transform\n",
    "*T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used*\n",
    "\n",
    "*T2. Confirm our pagination worked in the extract query by checking df length against total results of playlist json*\n",
    "\n",
    "*T3. Begin transforming the DataFrame to exactly what we want to load*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='T1'></a>\n",
    "\n",
    "**T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used**\n",
    "    - Here's a snippet of what our df will look like after we flatten the json out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>etag</th>\n",
       "      <th>id</th>\n",
       "      <th>snippet.publishedAt</th>\n",
       "      <th>snippet.channelId</th>\n",
       "      <th>snippet.title</th>\n",
       "      <th>snippet.description</th>\n",
       "      <th>snippet.thumbnails.default.url</th>\n",
       "      <th>snippet.thumbnails.default.width</th>\n",
       "      <th>snippet.thumbnails.default.height</th>\n",
       "      <th>...</th>\n",
       "      <th>snippet.thumbnails.high.url</th>\n",
       "      <th>snippet.thumbnails.high.width</th>\n",
       "      <th>snippet.thumbnails.high.height</th>\n",
       "      <th>snippet.channelTitle</th>\n",
       "      <th>snippet.playlistId</th>\n",
       "      <th>snippet.position</th>\n",
       "      <th>snippet.resourceId.kind</th>\n",
       "      <th>snippet.resourceId.videoId</th>\n",
       "      <th>contentDetails.videoId</th>\n",
       "      <th>contentDetails.videoPublishedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>youtube#playlistItem</td>\n",
       "      <td>JFzB7xf4Hx7Ji8Sf6KNAlCvsj50</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "      <td>2017-08-13T00:19:12Z</td>\n",
       "      <td>UCqjLgu2L35BoHNnhQLzmlfQ</td>\n",
       "      <td>Yee</td>\n",
       "      <td>Dinosauri bisesti dalle voci funeste. Original...</td>\n",
       "      <td>https://i.ytimg.com/vi/q6EoRBvdVPQ/default.jpg</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>...</td>\n",
       "      <td>https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg</td>\n",
       "      <td>480</td>\n",
       "      <td>360</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>0</td>\n",
       "      <td>youtube#video</td>\n",
       "      <td>q6EoRBvdVPQ</td>\n",
       "      <td>q6EoRBvdVPQ</td>\n",
       "      <td>2012-02-29T19:47:08Z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   kind                         etag  \\\n",
       "0  youtube#playlistItem  JFzB7xf4Hx7Ji8Sf6KNAlCvsj50   \n",
       "\n",
       "                                                  id   snippet.publishedAt  \\\n",
       "0  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  2017-08-13T00:19:12Z   \n",
       "\n",
       "          snippet.channelId snippet.title  \\\n",
       "0  UCqjLgu2L35BoHNnhQLzmlfQ           Yee   \n",
       "\n",
       "                                 snippet.description  \\\n",
       "0  Dinosauri bisesti dalle voci funeste. Original...   \n",
       "\n",
       "                   snippet.thumbnails.default.url  \\\n",
       "0  https://i.ytimg.com/vi/q6EoRBvdVPQ/default.jpg   \n",
       "\n",
       "   snippet.thumbnails.default.width  snippet.thumbnails.default.height  ...  \\\n",
       "0                               120                                 90  ...   \n",
       "\n",
       "                        snippet.thumbnails.high.url  \\\n",
       "0  https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg   \n",
       "\n",
       "   snippet.thumbnails.high.width  snippet.thumbnails.high.height  \\\n",
       "0                            480                             360   \n",
       "\n",
       "  snippet.channelTitle                  snippet.playlistId  snippet.position  \\\n",
       "0        kierancaspian  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo                 0   \n",
       "\n",
       "  snippet.resourceId.kind snippet.resourceId.videoId  contentDetails.videoId  \\\n",
       "0           youtube#video                q6EoRBvdVPQ             q6EoRBvdVPQ   \n",
       "\n",
       "  contentDetails.videoPublishedAt  \n",
       "0            2012-02-29T19:47:08Z  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.json_normalize(yt_json['items'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used*\n",
    "\n",
    "<a id='T2'></a>\n",
    "**T2. Confirm our pagination worked in the extract query by checking df length against total results of playlist json**\n",
    "    - yt_json['pageInfo']['totalResults'] is the total number of videos in the playlist\n",
    "    - if yt_json['pageInfo']['totalResults']==df.shape[0] then you're certain the json query populated all the videos from the playlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of videos returned: 311\n",
      "Number of rows in dataframe: 311\n",
      "All videos returned? True\n"
     ]
    }
   ],
   "source": [
    "playlist_items = pd.json_normalize(yt_json['items'])\n",
    "print(\"Number of videos returned: {}\".format(playlist_items.shape[0]))\n",
    "print(\"Number of rows in dataframe: {}\".format(playlist_items.shape[0]))\n",
    "print(\"All videos returned? {}\".format(yt_json['pageInfo']['totalResults']==playlist_items.shape[0]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used*\n",
    "\n",
    "*T2. Confirm our pagination worked in the extract query by checking df length against total results of playlist json*\n",
    "\n",
    "<a id='T3a'></a>\n",
    "**T3. Begin transforming the DataFrame to exactly what we want to load**\n",
    " - [ ] **A. Create clickable a clickable links, take a break and check out a video**\n",
    " - [ ] B. Write and use function to split column names into the desired format\n",
    " - [ ] C. Cast 'videopublishedat' as a DateTime object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://www.youtube.com/watch?v=q6EoRBvdVPQ&li...\n",
       "1      https://www.youtube.com/watch?v=8YWl7tDGUPA&li...\n",
       "2      https://www.youtube.com/watch?v=6bnanI9jXps&li...\n",
       "3      https://www.youtube.com/watch?v=IOzaT_uTNiU&li...\n",
       "4      https://www.youtube.com/watch?v=SBeYzoQPbu8&li...\n",
       "                             ...                        \n",
       "306    https://www.youtube.com/watch?v=5IXQ6f6eMxQ&li...\n",
       "307    https://www.youtube.com/watch?v=qPZymccwZm4&li...\n",
       "308    https://www.youtube.com/watch?v=9rq2_CSO65Y&li...\n",
       "309    https://www.youtube.com/watch?v=1tF2dF67Q2c&li...\n",
       "310    https://www.youtube.com/watch?v=wRRsXxE1KVY&li...\n",
       "Name: pl_url, Length: 311, dtype: object"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creates playlist url string to enter into browser for quick watchablity\n",
    "playlist_items['pl_url'] = 'https://www.youtube.com/watch?v=' + playlist_items['contentDetails.videoId'] + '&list=' + playlist_items['snippet.playlistId'] + '&index=' + playlist_items['snippet.position'].astype(str)\n",
    "webbrowser.open(playlist_items['pl_url'][random.randint(0,30)])\n",
    "playlist_items['pl_url'][0:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used*\n",
    "\n",
    "*T2. Confirm our pagination worked in the extract query by checking df length against total results of playlist json*\n",
    "\n",
    "<a id='T3b'></a>\n",
    "**T3. Begin transforming the DataFrame to exactly what we want to load**\n",
    " - [X] A. Create clickable a clickable links, take a break and check out a video\n",
    " - [ ] **B. Write and use function to split column names into the desired format and rename columns**\n",
    " - [ ] C. Cast 'videopublishedat' as a DateTime object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**split_col_names()** will extract well formatted column names to import into sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_col_names(list_i):\n",
    "    \"\"\"\n",
    "    Splits lists on '.' and returns the second parameter of the split. Due to the pd.json_normalize() and syntax:\n",
    "        'contentDetails.videoId' returns 'videoId'\n",
    "    \n",
    "    If there is no '.' in string then return the first value:\n",
    "        'kind' returns 'kind'\n",
    "\n",
    "    list i: input list\n",
    "    temp_list: returned list \n",
    "    \"\"\"\n",
    "    temp_list = []\n",
    "    list_i = [i.split(\".\") for i in list_i]\n",
    "    \n",
    "    for i in list_i: \n",
    "        if len(i)>1:\n",
    "            temp_list.append(i[1])\n",
    "        else: \n",
    "            temp_list.append(i[0])\n",
    "            \n",
    "    temp_list = [i.lower() for i in temp_list]\n",
    "    return temp_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select the cols to import into the db\n",
    "cols = ['snippet.title', 'snippet.description',\n",
    "       'pl_url', 'snippet.thumbnails.high.url',\n",
    "        'contentDetails.videoPublishedAt',\n",
    "       'snippet.channelTitle', 'snippet.position',\n",
    "        'snippet.resourceId.videoId', 'snippet.playlistId',\n",
    "       'etag','id']\n",
    "\n",
    "#rename columns and set data types\n",
    "new_cols = split_col_names(cols)\n",
    "final_playlist = playlist_items.rename(columns=dict(zip(cols, new_cols)))[new_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*T1. [pd.json_normalize()](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.json_normalize.html) is a very convenient method to flatten out json files and has many more kwargs that can be used*\n",
    "\n",
    "*T2. Confirm our pagination worked in the extract query by checking df length against total results of playlist json*\n",
    "\n",
    "<a id='T3c'></a>\n",
    "**T3. Begin transforming the DataFrame to exactly what we want to load**\n",
    " - [X] A. Create clickable a clickable links, take a break and check out a video\n",
    " - [X] B. Write and use function to split column names into the desired format and rename columns\n",
    " - [ ] **C. Cast 'videopublishedat' as a DateTime object**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_playlist['videopublishedat'] = pd.to_datetime(final_playlist['videopublishedat'].str[:10] + ' ' \n",
    "                                              + final_playlist['videopublishedat'].str[11:-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here's the final df we will be loading into postgre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>pl_url</th>\n",
       "      <th>thumbnails</th>\n",
       "      <th>videopublishedat</th>\n",
       "      <th>channeltitle</th>\n",
       "      <th>position</th>\n",
       "      <th>resourceid</th>\n",
       "      <th>playlistid</th>\n",
       "      <th>etag</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yee</td>\n",
       "      <td>Dinosauri bisesti dalle voci funeste. Original...</td>\n",
       "      <td>https://www.youtube.com/watch?v=q6EoRBvdVPQ&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg</td>\n",
       "      <td>2012-02-29 19:47:08</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>0</td>\n",
       "      <td>q6EoRBvdVPQ</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>JFzB7xf4Hx7Ji8Sf6KNAlCvsj50</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color red</td>\n",
       "      <td>Instagram: @jimmynez</td>\n",
       "      <td>https://www.youtube.com/watch?v=8YWl7tDGUPA&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/8YWl7tDGUPA/hqdefault.jpg</td>\n",
       "      <td>2014-09-06 03:39:52</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>1</td>\n",
       "      <td>8YWl7tDGUPA</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>dZ6i6SJWZcvZlrVQ2QuLDPKWEcU</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terrible Mall Commercial</td>\n",
       "      <td>Now that's a catchy tune!</td>\n",
       "      <td>https://www.youtube.com/watch?v=6bnanI9jXps&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/6bnanI9jXps/hqdefault.jpg</td>\n",
       "      <td>2014-08-17 20:45:59</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>2</td>\n",
       "      <td>6bnanI9jXps</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>B8HpEi2XY612lgHPLEQZBa0VZB8</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[HD] Sandra Annenberg Cai Ao Vivo no Programa ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.youtube.com/watch?v=IOzaT_uTNiU&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/IOzaT_uTNiU/hqdefault.jpg</td>\n",
       "      <td>2020-05-09 23:13:15</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>3</td>\n",
       "      <td>IOzaT_uTNiU</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>6gP0PMMV_sYMeVrykUdSZ0RmpCA</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name a yellow fruit</td>\n",
       "      <td></td>\n",
       "      <td>https://www.youtube.com/watch?v=SBeYzoQPbu8&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/SBeYzoQPbu8/hqdefault.jpg</td>\n",
       "      <td>2013-10-30 19:20:15</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>4</td>\n",
       "      <td>SBeYzoQPbu8</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>tn0QkHggUIceO1O1rg47GpRRTR0</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                                                Yee   \n",
       "1                                          color red   \n",
       "2                           Terrible Mall Commercial   \n",
       "3  [HD] Sandra Annenberg Cai Ao Vivo no Programa ...   \n",
       "4                                name a yellow fruit   \n",
       "\n",
       "                                         description  \\\n",
       "0  Dinosauri bisesti dalle voci funeste. Original...   \n",
       "1                               Instagram: @jimmynez   \n",
       "2                          Now that's a catchy tune!   \n",
       "3                                                      \n",
       "4                                                      \n",
       "\n",
       "                                              pl_url  \\\n",
       "0  https://www.youtube.com/watch?v=q6EoRBvdVPQ&li...   \n",
       "1  https://www.youtube.com/watch?v=8YWl7tDGUPA&li...   \n",
       "2  https://www.youtube.com/watch?v=6bnanI9jXps&li...   \n",
       "3  https://www.youtube.com/watch?v=IOzaT_uTNiU&li...   \n",
       "4  https://www.youtube.com/watch?v=SBeYzoQPbu8&li...   \n",
       "\n",
       "                                         thumbnails    videopublishedat  \\\n",
       "0  https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg 2012-02-29 19:47:08   \n",
       "1  https://i.ytimg.com/vi/8YWl7tDGUPA/hqdefault.jpg 2014-09-06 03:39:52   \n",
       "2  https://i.ytimg.com/vi/6bnanI9jXps/hqdefault.jpg 2014-08-17 20:45:59   \n",
       "3  https://i.ytimg.com/vi/IOzaT_uTNiU/hqdefault.jpg 2020-05-09 23:13:15   \n",
       "4  https://i.ytimg.com/vi/SBeYzoQPbu8/hqdefault.jpg 2013-10-30 19:20:15   \n",
       "\n",
       "    channeltitle  position   resourceid                          playlistid  \\\n",
       "0  kierancaspian         0  q6EoRBvdVPQ  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "1  kierancaspian         1  8YWl7tDGUPA  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "2  kierancaspian         2  6bnanI9jXps  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "3  kierancaspian         3  IOzaT_uTNiU  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "4  kierancaspian         4  SBeYzoQPbu8  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "\n",
       "                          etag  \\\n",
       "0  JFzB7xf4Hx7Ji8Sf6KNAlCvsj50   \n",
       "1  dZ6i6SJWZcvZlrVQ2QuLDPKWEcU   \n",
       "2  B8HpEi2XY612lgHPLEQZBa0VZB8   \n",
       "3  6gP0PMMV_sYMeVrykUdSZ0RmpCA   \n",
       "4  tn0QkHggUIceO1O1rg47GpRRTR0   \n",
       "\n",
       "                                                  id  \n",
       "0  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "1  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "2  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "3  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "4  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_playlist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Load_main'></a>\n",
    "### Load \n",
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "*L3. Create playlist TABLE in the new youtube_test DATABASE*\n",
    "- [ ] We'll have to connect to the new youtube_test DATABASE\n",
    "\n",
    "*L4. Use sqlalchemy to upload our DataFrame to our new playlists table*\n",
    "\n",
    "*L5. Confirm our DataFrame uploaded to our desired location*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='L1'></a>\n",
    "**L1.  Use psycopg2 to connect to our new Postgre DB**\n",
    "- To get familiar with psycopg2  we'll use it to connect to our new Postgre DB and create a few things\n",
    "    - psycopg2 is a standard package to connect from python to query postgres DBs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the sql and connect libraries for psycopg2\n",
    "from psycopg2.extensions import ISOLATION_LEVEL_AUTOCOMMIT\n",
    "from psycopg2 import sql, connect\n",
    "import psycopg2\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Here you'll need to configure your db connection info to use psycopg2\n",
    "- db_name = Every install of postgres comes with a stock db called postgres that houses schema information of the whole db \n",
    "- user = generally most people set up postgres as the default user on the initial install as well\n",
    "- host = the ip adress of the machine your db is located. if you db is on the same machine this query then \"localhost\" or \"127.0.0.1\" will work\n",
    "    - [There's no where like 127.0.0.1](https://www.lifewire.com/network-computer-special-ip-address-818385)\n",
    "- password = password of your db login "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a global string for the PostgreSQL db name\n",
    "db_name = \"postgres\"\n",
    "user = \"postgres\"\n",
    "host = \"127.0.0.1\" #192.168.1.206\n",
    "password = \"mypw\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### It is common convention to call your connection conn or con like we do here connecting to our db listed above\n",
    " - then we create a cur object from the conn.cursor() method \n",
    " - if your connection throws an exception it will print below, [happy debugging](https://www.postgresql.org/docs/12/errcodes-appendix.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 connection:\n",
      " dsn: 'user=postgres password=xxx dbname=postgres host=127.0.0.1', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "#Set up the connection string to your db\n",
    "try:\n",
    "    # declare a new PostgreSQL connection object\n",
    "    conn = connect(\n",
    "        dbname = db_name,\n",
    "        user = user,\n",
    "        host = host,\n",
    "        password = password\n",
    "    )\n",
    "\n",
    "    # print the connection if successful\n",
    "    print (\"psycopg2 connection:\\n\", str(conn).split('; ')[1])\n",
    "    cur = conn.cursor()\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)\n",
    "    conn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "<a id='L2'></a>\n",
    "**L2. Create a youtube_test DATABASE**\n",
    "- Below we use our cur object method execute to create a youtube_test DATABASE and playlists TABLE\n",
    "- This table will store the our final_playlist DataFrame\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 connect() ERROR: name 'con' is not defined\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    # Connect to PostgreSQL DBMS\n",
    "    conn = psycopg2.connect(\"user=postgres password='mypw'\");\n",
    "    con.set_isolation_level(ISOLATION_LEVEL_AUTOCOMMIT);\n",
    "\n",
    "    # Obtain a DB Cursor\n",
    "    cursor          = con.cursor();\n",
    "    name_Database   = \"youtube_test\";\n",
    "\n",
    "    # Drop table statement\n",
    "    sqlDropDatabase = \"DROP DATABASE IF EXISTS \" +name_Database+\";\" \n",
    "    \n",
    "    # Create table statement\n",
    "    sqlCreateDatabase = \"create database \"+name_Database+\";\"\n",
    "\n",
    "    # Drop and Create a table in PostgreSQL database\n",
    "    cursor.execute(sqlDropDatabase);\n",
    "    cursor.execute(sqlCreateDatabase);\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)\n",
    "\n",
    "conn.close() #closes connection to database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "<a id='L3'></a>\n",
    "**L3. Create playlist TABLE in the new youtube_test DATABASE**\n",
    "- [ ] **A. We'll have to connect to the new youtube_test DATABASE**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 connection:\n",
      " dsn: 'user=postgres password=xxx dbname=youtube_test host=127.0.0.1', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "db_name = 'youtube_test'\n",
    "#Set up the connection string to your db\n",
    "try:\n",
    "    # declare a new PostgreSQL connection object\n",
    "    conn = connect(\n",
    "        dbname = db_name,\n",
    "        user = user,\n",
    "        host = host,\n",
    "        password = password\n",
    "    )\n",
    "\n",
    "    # print the connection if successful\n",
    "    print (\"psycopg2 connection:\\n\", str(conn).split('; ')[1])\n",
    "    cur = conn.cursor()\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)\n",
    "    conn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "<a id='L3a'></a>\n",
    "**L3. Create playlist TABLE in the new youtube_test DATABASE**\n",
    "- A. [X] *We'll have to connect to the new youtube_test DATABASE*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "try: \n",
    "    cur.execute(\"\"\"\n",
    "    DROP TABLE IF EXISTS playlists;\n",
    "    \n",
    "    CREATE TABLE playlists (\n",
    "        title TEXT, \n",
    "        description TEXT,\n",
    "        pl_url TEXT,\n",
    "        thumbnails TEXT,\n",
    "        videopublishedat TIMESTAMP,\n",
    "        channeltitle TEXT,\n",
    "        position INTEGER,\n",
    "        resourceid TEXT, \n",
    "        playlistid TEXT,\n",
    "        etag TEXT,\n",
    "        id TEXT,\n",
    "        PRIMARY KEY (etag)\n",
    "        );\n",
    "    \"\"\")\n",
    "    conn.commit() #without this .commit() method the table won't write to the DataBase\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)   \n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "*L3. Create playlist TABLE in the new youtube_test DATABASE*\n",
    "- [X] We'll have to connect to the new youtube_test DATABASE\n",
    "\n",
    "<a id='L4'></a>\n",
    "**L4. Use sqlalchemy to upload our DataFrame to our new playlists table**\n",
    "- sqlalchemy is another common connection method used to read and write data to a db from python\n",
    "        - sqlalchemy really works like an [ORM](https://docs.sqlalchemy.org/en/13/core/engines.html) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "table_name = 'playlists'\n",
    "from sqlalchemy import create_engine\n",
    "engine = create_engine(\"postgresql://postgres:mypw@127.0.0.1/youtube_test\")\n",
    "conn = engine.connect()\n",
    "final_playlist.to_sql(name=table_name,con=conn,if_exists='append', index=False)\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "*L3. Create playlist TABLE in the new youtube_test DATABASE*\n",
    "   -  [X] *We'll have to connect to the new youtube_test DATABASE*\n",
    "\n",
    "*L4. Use sqlalchemy to upload our DataFrame to our new playlists table*\n",
    "\n",
    "<a id='L5a'></a>\n",
    "**L5. Confirm our DataFrame uploaded to our desired location**\n",
    "   - [ ] **A. Reconnect with psycopg2**\n",
    "   - [ ] B. Write function to get the column names of the table for our sql_df DataFrame\n",
    "        - get_cols is a utility function needed to find the column names from a postgres sql table\n",
    "   - [ ] C. query the playlists table to view your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psycopg2 connection:\n",
      " dsn: 'user=postgres password=xxx dbname=youtube_test host=127.0.0.1', closed: 0>\n"
     ]
    }
   ],
   "source": [
    "#Set up the connection string to your db\n",
    "try:\n",
    "    # declare a new PostgreSQL connection object\n",
    "    conn = connect(\n",
    "        dbname = db_name,\n",
    "        user = user,\n",
    "        host = host,\n",
    "        password = password\n",
    "    )\n",
    "\n",
    "    # print the connection if successful\n",
    "    print (\"psycopg2 connection:\\n\", str(conn).split('; ')[1])\n",
    "    cur = conn.cursor()\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)\n",
    "    conn = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "*L3. Create playlist TABLE in the new youtube_test DATABASE*\n",
    "   -  [X] *We'll have to connect to the new youtube_test DATABASE*\n",
    "\n",
    "*L4. Use sqlalchemy to upload our DataFrame to our new playlists table*\n",
    "\n",
    "<a id='L5b'></a>\n",
    "L5. **Confirm our DataFrame uploaded to our desired location**\n",
    "   - [X] *A. Reconnect with psycopg2*\n",
    "   - [ ] **B. Write function to get the column names of the table for our sql_df DataFrame**\n",
    "        - get_cols is a utility function needed to find the column names from a postgres sql table\n",
    "   - [ ] C. query the playlists table to view your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cols(table = None):\n",
    "    \"\"\"\n",
    "    function that gets the column names from a PostgreSQL table\n",
    "    \n",
    "    table: input table to retrieve cols form\n",
    "    columns: returns list table's cols\n",
    "    \"\"\"\n",
    "    # declare an empty list for the column names\n",
    "    columns = []\n",
    "\n",
    "    # declare cursor objects from the connection    \n",
    "    col_cursor = conn.cursor()\n",
    "\n",
    "    # concatenate string for query to get column names\n",
    "    # SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = 'some_table';\n",
    "    col_names_str = \"SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE \"\n",
    "    col_names_str += \"table_name = '{}';\".format( table )\n",
    "\n",
    "    # print the SQL string\n",
    "    print (\"col names pull sql query:\\n\", col_names_str)\n",
    "    \n",
    "    #NOTE: It’s best to use the sql.SQL() and sql.Identifier() \n",
    "    #modules to build the SQL statement for you, \n",
    "    #instead of just concatenating the string yourself. \n",
    "    #Doing this can help prevent SQL injection attacks.\n",
    "    try:\n",
    "        sql_object = sql.SQL(\n",
    "            # pass SQL statement to sql.SQL() method\n",
    "            col_names_str\n",
    "        ).format(\n",
    "            # pass the identifier to the Identifier() method\n",
    "            sql.Identifier( table )\n",
    "        )\n",
    "        \n",
    "        # execute the SQL string to get list with col names in a tuple\n",
    "        col_cursor.execute( sql_object )\n",
    "\n",
    "        # get the tuple element from the liast\n",
    "        col_names = ( col_cursor.fetchall() )\n",
    "\n",
    "        # iterate list of tuples and grab first element\n",
    "        for tup in col_names:\n",
    "\n",
    "            # append the col name string to the list\n",
    "            columns += [ tup[0] ]\n",
    "           \n",
    "        # close the cursor object to prevent memory leaks\n",
    "        col_cursor.close()\n",
    "        \n",
    "        # print list of tuples with column names\n",
    "        print (\"col names:\\n\", columns)\n",
    "\n",
    "    except Exception as err:\n",
    "        print (\"get_columns_names ERROR:\", err)\n",
    "\n",
    "    # return the list of column names\n",
    "    return columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*L1.  Use psycopg2 to connect to our new Postgre DB*\n",
    "\n",
    "*L2. Create a youtube_test DATABASE.*\n",
    "\n",
    "*L3. Create playlist TABLE in the new youtube_test DATABASE*\n",
    "   -  [X] *We'll have to connect to the new youtube_test DATABASE*\n",
    "\n",
    "*L4. Use sqlalchemy to upload our DataFrame to our new playlists table*\n",
    "\n",
    "<a id='L5c'></a>\n",
    "L5. **Confirm our DataFrame uploaded to our desired location**\n",
    "   - [X] *A. Reconnect with psycopg2*\n",
    "   - [X] *B. Write function to get the column names of the table for our sql_df DataFrame*\n",
    "        - get_cols is a utility function needed to find the column names from a postgres sql table\n",
    "   - [ ] **C. query the playlists table to view your data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "col names pull sql query:\n",
      " SELECT column_name FROM INFORMATION_SCHEMA.COLUMNS WHERE table_name = 'playlists';\n",
      "col names:\n",
      " ['title', 'description', 'pl_url', 'thumbnails', 'videopublishedat', 'channeltitle', 'position', 'resourceid', 'playlistid', 'etag', 'id']\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    cur.execute(\"\"\"\n",
    "    select * from playlists\n",
    "    \"\"\")\n",
    "    \n",
    "    sql_return = cur.fetchall()\n",
    "    \n",
    "    sql_df = pd.DataFrame(sql_return, columns = get_cols('playlists'))\n",
    "\n",
    "except Exception as err:\n",
    "    print (\"psycopg2 connect() ERROR:\", err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>pl_url</th>\n",
       "      <th>thumbnails</th>\n",
       "      <th>videopublishedat</th>\n",
       "      <th>channeltitle</th>\n",
       "      <th>position</th>\n",
       "      <th>resourceid</th>\n",
       "      <th>playlistid</th>\n",
       "      <th>etag</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yee</td>\n",
       "      <td>Dinosauri bisesti dalle voci funeste. Original...</td>\n",
       "      <td>https://www.youtube.com/watch?v=q6EoRBvdVPQ&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg</td>\n",
       "      <td>2012-02-29 19:47:08</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>0</td>\n",
       "      <td>q6EoRBvdVPQ</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>JFzB7xf4Hx7Ji8Sf6KNAlCvsj50</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>color red</td>\n",
       "      <td>Instagram: @jimmynez</td>\n",
       "      <td>https://www.youtube.com/watch?v=8YWl7tDGUPA&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/8YWl7tDGUPA/hqdefault.jpg</td>\n",
       "      <td>2014-09-06 03:39:52</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>1</td>\n",
       "      <td>8YWl7tDGUPA</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>dZ6i6SJWZcvZlrVQ2QuLDPKWEcU</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Terrible Mall Commercial</td>\n",
       "      <td>Now that's a catchy tune!</td>\n",
       "      <td>https://www.youtube.com/watch?v=6bnanI9jXps&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/6bnanI9jXps/hqdefault.jpg</td>\n",
       "      <td>2014-08-17 20:45:59</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>2</td>\n",
       "      <td>6bnanI9jXps</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>B8HpEi2XY612lgHPLEQZBa0VZB8</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[HD] Sandra Annenberg Cai Ao Vivo no Programa ...</td>\n",
       "      <td></td>\n",
       "      <td>https://www.youtube.com/watch?v=IOzaT_uTNiU&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/IOzaT_uTNiU/hqdefault.jpg</td>\n",
       "      <td>2020-05-09 23:13:15</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>3</td>\n",
       "      <td>IOzaT_uTNiU</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>6gP0PMMV_sYMeVrykUdSZ0RmpCA</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>name a yellow fruit</td>\n",
       "      <td></td>\n",
       "      <td>https://www.youtube.com/watch?v=SBeYzoQPbu8&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/SBeYzoQPbu8/hqdefault.jpg</td>\n",
       "      <td>2013-10-30 19:20:15</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>4</td>\n",
       "      <td>SBeYzoQPbu8</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>tn0QkHggUIceO1O1rg47GpRRTR0</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>test video please do not watch</td>\n",
       "      <td>idk how this video is still so popular, check ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=5IXQ6f6eMxQ&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/5IXQ6f6eMxQ/hqdefault.jpg</td>\n",
       "      <td>2015-02-18 13:27:46</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>306</td>\n",
       "      <td>5IXQ6f6eMxQ</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>TmgHYZbsFscgyGOd9JZtJ-bpq_k</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>Cry Me To The Moon</td>\n",
       "      <td>Original is \"Fly me to the Moon\"\\n\\nPatreon: h...</td>\n",
       "      <td>https://www.youtube.com/watch?v=qPZymccwZm4&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/qPZymccwZm4/hqdefault.jpg</td>\n",
       "      <td>2012-12-27 06:02:41</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>307</td>\n",
       "      <td>qPZymccwZm4</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>GNj2Mwp4gTkAPdePekg3PfNhYYI</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>Evangelion in a Nutshell</td>\n",
       "      <td>If you have a weak heart or liver, I strongly ...</td>\n",
       "      <td>https://www.youtube.com/watch?v=9rq2_CSO65Y&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/9rq2_CSO65Y/hqdefault.jpg</td>\n",
       "      <td>2013-01-19 19:06:29</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>308</td>\n",
       "      <td>9rq2_CSO65Y</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>cpGb5RuXR8dI8_LfkO8R15rxY7k</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>\"GOLD BOND LIQUI-SHAQ\" - TV SHERIFF VIDEO REMIX</td>\n",
       "      <td>A new ditty from TV SHERIFF!! Original sponsor...</td>\n",
       "      <td>https://www.youtube.com/watch?v=1tF2dF67Q2c&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/1tF2dF67Q2c/hqdefault.jpg</td>\n",
       "      <td>2014-12-03 08:46:28</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>309</td>\n",
       "      <td>1tF2dF67Q2c</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>juaEoG5hoHl-zX0DFu10fvw0DLs</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>John Cena Prank Call</td>\n",
       "      <td>WWE</td>\n",
       "      <td>https://www.youtube.com/watch?v=wRRsXxE1KVY&amp;li...</td>\n",
       "      <td>https://i.ytimg.com/vi/wRRsXxE1KVY/hqdefault.jpg</td>\n",
       "      <td>2014-03-11 14:27:48</td>\n",
       "      <td>kierancaspian</td>\n",
       "      <td>310</td>\n",
       "      <td>wRRsXxE1KVY</td>\n",
       "      <td>PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo</td>\n",
       "      <td>_k23SXKkyzuZHIPj5XFptFWGvtQ</td>\n",
       "      <td>UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>311 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0                                                  Yee   \n",
       "1                                            color red   \n",
       "2                             Terrible Mall Commercial   \n",
       "3    [HD] Sandra Annenberg Cai Ao Vivo no Programa ...   \n",
       "4                                  name a yellow fruit   \n",
       "..                                                 ...   \n",
       "306                     test video please do not watch   \n",
       "307                                 Cry Me To The Moon   \n",
       "308                           Evangelion in a Nutshell   \n",
       "309    \"GOLD BOND LIQUI-SHAQ\" - TV SHERIFF VIDEO REMIX   \n",
       "310                               John Cena Prank Call   \n",
       "\n",
       "                                           description  \\\n",
       "0    Dinosauri bisesti dalle voci funeste. Original...   \n",
       "1                                 Instagram: @jimmynez   \n",
       "2                            Now that's a catchy tune!   \n",
       "3                                                        \n",
       "4                                                        \n",
       "..                                                 ...   \n",
       "306  idk how this video is still so popular, check ...   \n",
       "307  Original is \"Fly me to the Moon\"\\n\\nPatreon: h...   \n",
       "308  If you have a weak heart or liver, I strongly ...   \n",
       "309  A new ditty from TV SHERIFF!! Original sponsor...   \n",
       "310                                                WWE   \n",
       "\n",
       "                                                pl_url  \\\n",
       "0    https://www.youtube.com/watch?v=q6EoRBvdVPQ&li...   \n",
       "1    https://www.youtube.com/watch?v=8YWl7tDGUPA&li...   \n",
       "2    https://www.youtube.com/watch?v=6bnanI9jXps&li...   \n",
       "3    https://www.youtube.com/watch?v=IOzaT_uTNiU&li...   \n",
       "4    https://www.youtube.com/watch?v=SBeYzoQPbu8&li...   \n",
       "..                                                 ...   \n",
       "306  https://www.youtube.com/watch?v=5IXQ6f6eMxQ&li...   \n",
       "307  https://www.youtube.com/watch?v=qPZymccwZm4&li...   \n",
       "308  https://www.youtube.com/watch?v=9rq2_CSO65Y&li...   \n",
       "309  https://www.youtube.com/watch?v=1tF2dF67Q2c&li...   \n",
       "310  https://www.youtube.com/watch?v=wRRsXxE1KVY&li...   \n",
       "\n",
       "                                           thumbnails    videopublishedat  \\\n",
       "0    https://i.ytimg.com/vi/q6EoRBvdVPQ/hqdefault.jpg 2012-02-29 19:47:08   \n",
       "1    https://i.ytimg.com/vi/8YWl7tDGUPA/hqdefault.jpg 2014-09-06 03:39:52   \n",
       "2    https://i.ytimg.com/vi/6bnanI9jXps/hqdefault.jpg 2014-08-17 20:45:59   \n",
       "3    https://i.ytimg.com/vi/IOzaT_uTNiU/hqdefault.jpg 2020-05-09 23:13:15   \n",
       "4    https://i.ytimg.com/vi/SBeYzoQPbu8/hqdefault.jpg 2013-10-30 19:20:15   \n",
       "..                                                ...                 ...   \n",
       "306  https://i.ytimg.com/vi/5IXQ6f6eMxQ/hqdefault.jpg 2015-02-18 13:27:46   \n",
       "307  https://i.ytimg.com/vi/qPZymccwZm4/hqdefault.jpg 2012-12-27 06:02:41   \n",
       "308  https://i.ytimg.com/vi/9rq2_CSO65Y/hqdefault.jpg 2013-01-19 19:06:29   \n",
       "309  https://i.ytimg.com/vi/1tF2dF67Q2c/hqdefault.jpg 2014-12-03 08:46:28   \n",
       "310  https://i.ytimg.com/vi/wRRsXxE1KVY/hqdefault.jpg 2014-03-11 14:27:48   \n",
       "\n",
       "      channeltitle  position   resourceid                          playlistid  \\\n",
       "0    kierancaspian         0  q6EoRBvdVPQ  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "1    kierancaspian         1  8YWl7tDGUPA  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "2    kierancaspian         2  6bnanI9jXps  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "3    kierancaspian         3  IOzaT_uTNiU  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "4    kierancaspian         4  SBeYzoQPbu8  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "..             ...       ...          ...                                 ...   \n",
       "306  kierancaspian       306  5IXQ6f6eMxQ  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "307  kierancaspian       307  qPZymccwZm4  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "308  kierancaspian       308  9rq2_CSO65Y  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "309  kierancaspian       309  1tF2dF67Q2c  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "310  kierancaspian       310  wRRsXxE1KVY  PLFsQleAWXsj_4yDeebiIADdH5FMayBiJo   \n",
       "\n",
       "                            etag  \\\n",
       "0    JFzB7xf4Hx7Ji8Sf6KNAlCvsj50   \n",
       "1    dZ6i6SJWZcvZlrVQ2QuLDPKWEcU   \n",
       "2    B8HpEi2XY612lgHPLEQZBa0VZB8   \n",
       "3    6gP0PMMV_sYMeVrykUdSZ0RmpCA   \n",
       "4    tn0QkHggUIceO1O1rg47GpRRTR0   \n",
       "..                           ...   \n",
       "306  TmgHYZbsFscgyGOd9JZtJ-bpq_k   \n",
       "307  GNj2Mwp4gTkAPdePekg3PfNhYYI   \n",
       "308  cpGb5RuXR8dI8_LfkO8R15rxY7k   \n",
       "309  juaEoG5hoHl-zX0DFu10fvw0DLs   \n",
       "310  _k23SXKkyzuZHIPj5XFptFWGvtQ   \n",
       "\n",
       "                                                    id  \n",
       "0    UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "1    UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "2    UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "3    UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "4    UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "..                                                 ...  \n",
       "306  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "307  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "308  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "309  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "310  UExGc1FsZUFXWHNqXzR5RGVlYmlJQURkSDVGTWF5QmlKby...  \n",
       "\n",
       "[311 rows x 11 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sql_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
